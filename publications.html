<!DOCTYPE html>
<html lang="en">


<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=900">
    <title>Publications</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="icon" href="assets/icon.jpg">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Castoro"
        rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Noto+Sans:400,700,400italic,700italic"
        rel="stylesheet">    
    <!-- <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet'> -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
    <style>
        :root {
            --highlight-color: rgba(255, 249, 196, 0.79)
        }
    </style>
</head>


<body>
    <table width="900" border="0" align="center" cellspacing="0" cellpadding="20">
    <tr>
        <td style="width:25%; vertical-align:middle; padding-right: 10px;">
            <a href="index.html"><img src="assets/logo.png" height="100"></a>
        </td>

        <td style="width:15%; vertical-align:middle; text-align:center; padding-right: 5px;">
            <a href="people.html" style="font-size: 22px; color:black">People</a>
        </td>

        <td style="width:15%; vertical-align:middle; text-align:center; padding-right: 10px;">
            <a href="publications.html" style="font-size: 22px; color:black">Publications</a>
        </td>

        <td style="width:15%; vertical-align:middle; text-align:center; padding-right: 0px;">
            <a href="research.html" style="font-size: 22px; color:black">Research</a>
        </td>

        <td style="width:15%; vertical-align:middle; text-align:center; padding-right: 0px;">
            <a href="robots.html" style="font-size: 22px; color:black">Robots</a>
        </td>

        <td style="width:15%; vertical-align:middle; text-align:center; padding-right: 0px;">
            <a href="join.html" style="font-size: 22px; color:black">Join</a>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td width="100%" valign="middle">
            <p> 
                <!-- Check out the <a href="https://scholar.google.com/citations?user=joR1Z4UAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a> page for a full and up-to-date publication list.  -->
                <sup>*</sup> denotes equal contribution and <sup>&dagger;</sup> denotes equal advising. Representative papers are <span style="background-color: var(--highlight-color)">highlighted</span>.
            </p>
        </td>
    </tr>
    </table>
   
    <br>

   <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td width="100%" valign="middle">
            <heading>Preprints</heading>
        </td>
    </tr>
    </table>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_EADP.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>UMI-on-Air: Embodiment-Aware Guidance for Embodiment-Agnostic Visuomotor Policies</papertitle>
            <br>
            Harsh Gupta, Xiaofeng Guo, Huy Ha, Chuer Pan, Muqing Cao, Dongjae Lee, Sebastian Sherer, Shuran Song, Guanya Shi
            <br>
            <a href="https://arxiv.org/abs/2510.02614" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://umi-on-air.github.io/" target="_blank"><i class="fas fa-globe"></i> website</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: EADP steers UMI's embodiment-agnostic diffusion policy using the gradient of the low-level controller's tracking cost for cross-embodiment.
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_ResFiT.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Residual Off-Policy RL for Finetuning Behavior Cloning Policies</papertitle>
            <br>
            Lars Ankile, Zhenyu Jiang, Rocky Duan, Guanya Shi, Pieter Abbeel, Anusha Nagabandi
            <br>
            <a href="https://arxiv.org/abs/2509.19301" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://residual-offpolicy-rl.github.io/" target="_blank"><i class="fas fa-globe"></i> website</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: ResFiT is a sample-efficient residual RL method that performs real-world RL directly on a wheeled humanoid with two dex hands.
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_OmniRetarget.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction</papertitle>
            <br>
            Lujie Yang<sup>*</sup>, Xiaoyu Huang<sup>*</sup>, Zhen Wu<sup>*</sup>, Angjoo Kanazawa<sup>&dagger;</sup>, Pieter Abbeel<sup>&dagger;</sup>, Carmelo Sferrazza<sup>&dagger;</sup>, C. Karen Liu<sup>&dagger;</sup>, Rocky Duan<sup>&dagger;</sup>, Guanya Shi<sup>&dagger;</sup>
            <br>
            <a href="https://arxiv.org/abs/2509.26633" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://omniretarget.github.io/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://huggingface.co/datasets/omniretarget/OmniRetarget_Dataset" target="_blank"><i class="fas fa-database"></i> dataset</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: High-quality interaction-preserving motion reference generation that enables agile whole-body skills with minimal RL tracking.
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_HDMI.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>HDMI: Learning Interactive Humanoid Whole-Body Control from Human Videos</papertitle>
            <br>
            Haoyang Weng, Yitang Li, Nikhil Sobanbabu, Zihan Wang, Zhengyi Luo, Tairan He, Deva Ramanan, Guanya Shi
            <br>
            <a href="https://arxiv.org/abs/2509.16757" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://hdmi-humanoid.github.io/#/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/LeCAR-Lab/HDMI" target="_blank"><i class="fas fa-code"></i> code</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: From human videos, HDMI learns robust humanoid loco-manipulation skills (e.g., opening a door continuously for 67 times). 
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_LeVERB.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction</papertitle>
            <br>
            Haoru Xue<sup>*</sup>, Xiaoyu Huang<sup>*</sup>, Dantong Niu<sup>*</sup>, Qiayuan Liao<sup>*</sup>, Thomas Kragerud, Jan Tommy Gravdahl, Xue Bin Peng, Guanya Shi, Trevor Darrell, Koushil Screenath, Shankar Sastry
            <br>
            <a href="https://arxiv.org/abs/2506.13751" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://ember-lab-berkeley.github.io/LeVERB-Website/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://huggingface.co/datasets/ember-lab-berkeley/LeVERB-Bench-Dataset" target="_blank"><i class="fas fa-database"></i> dataset</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: LeVERB is a whole-body humanoid VLA, via learning an expressive and executable latent action vocabulary to bridge system 1 and system 2.
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='assets/FALCON.gif' width="95%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>FALCON: Learning Force-Adaptive Humanoid Loco-Manipulation</papertitle>
            <br>
            Yuanhang Zhang, Yifu Yuan, Prajwal Gurunath, Tairan He, Shayegan Omidshafiei, Ali-akbar Agha-mohammadi, Marcell Vazquez-Chanlatte, Liam Pedersen, Guanya Shi
            <br>
            <a href="https://arxiv.org/abs/2505.06776" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://lecar-lab.github.io/falcon-humanoid/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/LeCAR-Lab/FALCON/" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: FALCON enables various heavy-duty humanoid loco-manipulation tasks via a new dual-agent force-adaptive RL framework.
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_TDMPC_Square.gif' width="95%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>TD-M(PC)<sup>2</sup>: Improving Temporal Difference MPC Through Policy Constraint</papertitle>
            <br>
            Haotian Lin, Pengcheng Wang, Jeff Schneider, Guanya Shi
            <br>
            <a href="https://arxiv.org/abs/2502.03550v1" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://darthutopian.github.io/tdmpc_square/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/DarthUtopian/tdmpc_square_public" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We observe the value overestimation issue in planner-based MBRL and propose a policy constraint solution with SOTA performance.
        </td>
    </tr>
    </table>

    <br> 
    <br>  

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td width="100%" valign="middle">
            <heading>2025</heading>
        </td>
    </tr>
    </table>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_SPI_Active.gif' width="95%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Sampling-Based System Identification with Active Exploration for Legged Robot Sim2Real Learning</papertitle>
            <br>
            Nikhil Sobanbabu<sup>*</sup>, Guanqi He<sup>*</sup>, Tairan He, Yuxiang Yang, Guanya Shi
            <br>
            <em>Conference on Robot Learning (CoRL)</em>, 2025
            <br>
            <p style="color: orange; margin: 0px 0;">(Oral Presentation)</p>
            <a href="https://arxiv.org/abs/2505.14266" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://lecar-lab.github.io/spi-active_/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/LeCAR-Lab/SPI-Active" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: SPI-Active is a general system ID tool based on parallel sampling-based optimization and active exploration, for legged sim2real learning.
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_HumanPolicy.avif' width="95%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Humanoid Policy ~ Human Policy</papertitle>
            <br>
            Ri-Zhao Qiu<sup>*</sup>, Shiqi Yang<sup>*</sup>, Xuxin Cheng<sup>*</sup>, Chaitanya Chawla<sup>*</sup>, Jialong Li, Tairan He, Ge Yan, David J. Yoon, Ryan Hoque, Lars Paulsen, Ge Yang, Jian Zhang, Sha Yi, Guanya Shi, Xiaolong Wang
            <br>
            <em>Conference on Robot Learning (CoRL)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2503.13441" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://human-as-robot.github.io/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/RogerQi/human-policy" target="_blank"><i class="fas fa-code"></i> code</a> &nbsp
            <a href="https://huggingface.co/datasets/RogerQi/PH2D" target="_blank"><i class="fas fa-database"></i> dataset</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: Co-training humanoid manipulation policy with egocentric human data using a unified "human-centric state-action space".
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_SoFTA.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Hold My Beer: Learning Gentle Humanoid Locomotion and End-Effector Stabilization Control</papertitle>
            <br>
            Yitang Li, Yuanhang Zhang, Wenli Xiao, Chaoyi Pan, Haoyang Weng, Guanqi He, Tairan He, Guanya Shi
            <br>
            <em>Conference on Robot Learning (CoRL)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2505.24198" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://lecar-lab.github.io/SoFTA/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/LeCAR-Lab/SoFTA" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: SoFTA is a slow-fast two-agent sim2real RL framework achieving human-level end-effector stability for humanoids.
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_RAMBO.gif' width="95%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>RAMBO: RL-augmented Model-based Optimal Control for Whole-body Loco-manipulation</papertitle>
            <br>
            Jin Cheng, Dongho Kang, Gabriele Fadini, Guanya Shi, Stelian Coros
            <br>
            <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2504.06662" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://jin-cheng.me/rambo.github.io/" target="_blank"><i class="fas fa-globe"></i> website</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We integrate model-based reaction force optimization and RL, to get the best of both worlds for accurate and robust loco-manipulation.
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_Survey.png' width="56%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Humanoid Locomotion and Manipulation: Current Progress and Challenges in Control, Planning, and Learning</papertitle>
            <br>
            Zhaoyuan Gu, Junheng Li, Wenlan Shen, Wenhao Yu, Zhaoming Xie, Stephen McCrory, Xianyi Cheng, Abdulaziz Shamsah, Robert Griffin, C. Karen Liu, Abderrahmane Kheddar, Xue Bin Peng, Yuke Zhu, Guanya Shi, Quan Nguyen, Gordon Cheng, Huijun Gao<sup>&dagger;</sup>, Ye Zhao<sup>&dagger;</sup>
            <br>
            <em>Transactions on Mechatronics</em>, 2025            
            <br>
            <a href="https://arxiv.org/abs/2501.02116" target="_blank"><i class="far fa-file"></i> paper</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: A survey paper covering control, planning, and learning methods for humanoid locomotion and manipulation.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='assets/ASAP.gif' width="95%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>ASAP: Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills</papertitle>
            <br>
            Tairan He<sup>*</sup>, Jiawei Gao<sup>*</sup>, Wenli Xiao<sup>*</sup>, Yuanhang Zhang<sup>*</sup>, Zi Wang, Jiashun Wang, Zhengyi Luo, Guanqi He, Nikhil Sobanbab, Chaoyi Pan, Zeji Yi, Guannan Qu, Kris Kitani, Jessica Hodgins, Linxi "Jim" Fan, Yuke Zhu, Changliu Liu, Guanya Shi
            <br>
            <em>Robotics: Science and Systems (RSS)</em>, 2025            
            <br>
            <a href="https://arxiv.org/abs/2502.01143" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://agile.human2humanoid.com/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/LeCAR-Lab/ASAP" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: ASAP learns agile whole-body humanoid motions via learning a residual action model from the real world to align sim and real physics.
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_Flying_Hand.gif' width="95%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Flying Hand: End-Effector-Centric Framework for Versatile Aerial Manipulation Teleoperation and Policy Learning</papertitle>
            <br>
            Guanqi He<sup>*</sup>, Xiaofeng Guo<sup>*</sup>, Luyi Tang, Yuanhang Zhang, Mohammadreza Mousaei, Jiahe Xu, Junyi Geng, Sebastian Scherer, Guanya Shi
            <br>
            <em>Robotics: Science and Systems (RSS)</em>, 2025            
            <br>
            <a href="https://arxiv.org/abs/2407.05587" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://lecar-lab.github.io/flying_hand/" target="_blank"><i class="fas fa-globe"></i> website</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: A general-purpose aerial manipulation framework with an EE-centric interface that bridges whole-body control and policy learning.
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_BAS.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Bridging Adaptivity and Safety: Learning Agile Collision-Free Locomotion Across Varied Physics</papertitle>
            <br>
            Yichao Zhong, Chong Zhang, Tairan He, Guanya Shi
            <br>
            <em>Conference on Learning for Dynamics and Control (L4DC)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2501.04276" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://adaptive-safe-locomotion.github.io/" target="_blank"><i class="fas fa-code"></i> website</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We propose a learning-based locomotion framework that is agile, safe, and adpative in dynamic environments.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_DIAL-MPC.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Full-Order Sampling-Based MPC for Torque-Level Locomotion Control via Diffusion-Style Annealing</papertitle>
            <br>
            Haoru Xue<sup>*</sup>, Chaoyi Pan<sup>*</sup>, Zeji Yi, Guannan Qu, Guanya Shi
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2025
            <br>
            <p style="color: orange; margin: 0px 0;">(Best Paper Award Finalist)</p>
            <a href="https://arxiv.org/abs/2409.15610" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://lecar-lab.github.io/dial-mpc/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/LeCAR-Lab/dial-mpc" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: DIAL-MPC is the first training-free method achieving real-time whole-body torque control using full-order dynamics.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_HOVER.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>HOVER: Versatile Neural Whole-Body Controller for Humanoid Robots</papertitle>
            <br>
            Tairan He<sup>*</sup>, Wenli Xiao<sup>*</sup>, Toru Lin, Zhengyi Luo, Zhenjia Xu, Zhenyu Jiang, Jan Kautz, Changliu Liu, Guanya Shi, Xiaolong Wang, Linxi Fan<sup>&dagger;</sup>, Yuke Zhu<sup>&dagger;</sup>
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2410.21229" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://hover-versatile-humanoid.github.io/" target="_blank"><i class="fas fa-globe"></i> website</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: HOVER unifies many humanoid whole-body control modes to one policy that supports diverse control modes and outperforms each specialist.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_AnyCar.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>AnyCar to Anywhere: Learning Universal Dynamics Model for Agile and Adaptive Mobility</papertitle>
            <br>
            Wenli Xiao<sup>*</sup>, Haoru Xue<sup>*</sup>, Tony Tao, Dvij Kalaria, John M. Dolan, Guanya Shi
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2409.15783" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://lecar-lab.github.io/anycar/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/LeCAR-Lab/anycar" target="_blank"><i class="fas fa-code"></i> code</a> &nbsp
            <a href="https://spectrum.ieee.org/video-friday-mobile-robot-upgrades" target="_blank"><i class="fas fa-newspaper"></i> IEEE Spectrum</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: AnyCar is a transformer-based dynamics model that can adapt to various vehicles, environments, state estimators, and tasks.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_JumpingCoD.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Agile Continuous Jumping in Discontinuous Terrains</papertitle>
            <br>
            Yuxiang Yang, Guanya Shi, Changyi Lin, Xiangyun Meng, Rosario Scalise, Mateo Guaman Castro, Wenhao Yu, Tingnan Zhang, Ding Zhao, Jie Tan, Byron Boots
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2409.10923" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://yxyang.github.io/jumping_cod/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/yxyang/jumping_cod" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: Continuous, agile, and autonomous quadrupedal jumping via hierarchical model-free RL and model-based control.           
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_SSML-AC.png' width="62%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Self-Supervised Meta-Learning for All-Layer DNN-Based Adaptive Control with Stability Guarantees</papertitle>
            <br>
            Guanqi He, Yogita Choudhary, Guanya Shi
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2410.07575" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://sites.google.com/view/ssml-ac-project" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/LeCAR-Lab/SSML-AC/tree/main" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: Pretrain a residual dynamics DNN using meta-learning and fine-tune the whole DNN online using adaptive control with stability guarantees.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_PDOMP.png' width="60%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Propagative Distance Optimization for Motion Planning</papertitle>
            <br>
            Yu Chen, Jinyun Xu, Yilin Cai, Ting-Wei Wong, Zhongqiang Ren, Howie Choset, Guanya Shi
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2025
            <br>
            <a href="https://drive.google.com/file/d/17KRTaoDTP2KOWd8UxQZlynEN1Uo3FjA7/view" target="_blank"><i class="far fa-file"></i> paper</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: Using the distance-based kinematics formulations, we develop an efficient motion planning algorithm PDOMP.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_MPPI_uncertainty.png' width="95%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Agile Mobility with Rapid Online Adaptation via Meta-Learning and Uncertainty-Aware MPPI</papertitle>
            <br>
            Dvij Kalaria, Haoru Xue, Wenli Xiao, Tony Tao, Guanya Shi, John Dolan
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2410.06565" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://sites.google.com/view/meta-learning-model-adaptation" target="_blank"><i class="fas fa-globe"></i> website</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: Meta-learn a vehicle dynamics model ensemble and use uncertainty-aware MPPI for control.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2025_Q_Filter.png' width="95%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Q-Learning-Based Model-Free Safety Filter</papertitle>
            <br>
            Guo Ning Sue<sup>*</sup>, Yogita Choudhary<sup>*</sup>, Richard Desatnik, Carmel Majidi, John Dolan, Guanya Shi
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2025
            <br>
            <a href="https://arxiv.org/abs/2411.19809" target="_blank"><i class="far fa-file"></i> paper</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We introduce a novel safety reward formulaiton and use Q-value functions to safeguard task policies.
            </p>
        </td>
    </tr>
    </table>

    <br>
    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td width="100%" valign="middle">
            <heading>2024</heading>
        </td>
    </tr>
    </table>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_MBD.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Model-Based Diffusion for Trajectory Optimization</papertitle>
            <br>
            Chaoyi Pan<sup>*</sup>, Zeji Yi<sup>*</sup>, Guanya Shi<sup>&dagger;</sup>, Guannan Qu<sup>&dagger;</sup>
            <br>
            <em>Neural Information Processing Systems (NeurIPS)</em>, 2024
            <br>
            <a href="https://drive.google.com/file/d/1kPjD79Cfr9spWulWNVFMRHqTE-mjbGAp/view?usp=sharing" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://lecar-lab.github.io/mbd/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/LeCAR-Lab/model-based-diffusion" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: MBD is a diffusion-based traj optimization method that directly computes the score function using models without any external data. 
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_flying_calligrapher.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Flying Calligrapher: Contact-Aware Motion and Force Planning and Control for Aerial Manipulation</papertitle>
            <br>
            Xiaofeng Guo<sup>*</sup>, Guanqi He<sup>*</sup>, Jiahe Xu, Mohammadreza Mousaei, Junyi Geng, Sebastian Scherer, Guanya Shi
            <br>
            <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2407.05587" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://xiaofeng-guo.github.io/flying-calligrapher/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://spectrum.ieee.org/video-friday-unitree-talks-robots" target="_blank"><i class="fas fa-newspaper"></i> IEEE Spectrum</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: Flying calligrapher enables precise hybrid motion and contact force control for an aerial manipulator in various drawing tasks.              
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='assets/OmniH2O.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>OmniH2O: Universal and Dexterous Human-to-Humanoid Whole-Body Teleoperation and Learning</papertitle>
            <br>
            Tairan He<sup>*</sup>, Zhengyi Luo<sup>*</sup>, Xialin He<sup>*</sup>, Wenli Xiao, Chong Zhang, Weinan Zhang, Kris Kitani, Changliu Liu, Guanya Shi
            <br>
            <em>Conference on Robot Learning (CoRL)</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2406.08858" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://omni.human2humanoid.com/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://cmu.box.com/s/kmayzq5ax2rxvwn97s0hzz0aq5vws9io" target="_blank"><i class="fas fa-database"></i> dataset</a> &nbsp
            <a href="https://github.com/LeCAR-Lab/human2humanoid" target="_blank"><i class="fas fa-code"></i> code</a> &nbsp
            <a href="https://spectrum.ieee.org/video-friday-drone-vs-flying-canoe" target="_blank"><i class="fas fa-newspaper"></i> IEEE Spectrum</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: OmniH2O provides a universal whole-body humanoid control interface that enables diverse teleoperation and autonomy methods.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='assets/WoCoCo.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>WoCoCo: Learning Whole-Body Humanoid Control with Sequential Contacts</papertitle>
            <br>
            Chong Zhang<sup>*</sup>, Wenli Xiao<sup>*</sup>, Tairan He, Guanya Shi
            <br>
            <em>Conference on Robot Learning (CoRL)</em>, 2024
            <p style="color: orange; margin: 0px 0;">(Oral Presentation)</p>
            <a href="https://arxiv.org/abs/2406.06005" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://lecar-lab.github.io/wococo/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://spectrum.ieee.org/video-friday-drone-vs-flying-canoe" target="_blank"><i class="fas fa-newspaper"></i> IEEE Spectrum</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: WoCoCo is a task-agnostic skill learning framework without any motion priors, by decomposing long-horizon tasks into contact sequences.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='assets/H2O.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Learning Human-to-Humanoid Real-Time Whole-Body Teleoperation</papertitle>
            <br>
            Tairan He<sup>*</sup>, Zhengyi Luo<sup>*</sup>, Wenli Xiao, Chong Zhang, Kris Kitani, Changliu Liu, Guanya Shi 
            <br>
            <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2024
            <p style="color: orange; margin: 0px 0;">(Oral Presentation)</p>
            <a href="https://arxiv.org/abs/2403.04436" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://human2humanoid.com/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/LeCAR-Lab/human2humanoid" target="_blank"><i class="fas fa-code"></i> code</a> &nbsp
            <a href="https://spectrum.ieee.org/video-friday-human-to-humanoid" target="_blank"><i class="fas fa-newspaper"></i> IEEE Spectrum</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: H2O enables real-time whole-body teleoperation of a full-sized humanoid to perform tasks like pick and place, walking, kicking, boxing, etc.
            </p>
        </td>
    </tr>
    </table>

    <br>  

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='assets/abs.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Agile But Safe: Learning Collision-Free High-Speed Legged Locomotion</papertitle>
            <br>
            Tairan He<sup>*</sup>, Chong Zhang<sup>*</sup>, Wenli Xiao, Guanqi He, Changliu Liu, Guanya Shi 
            <br>
            <em>Robotics: Science and Systems (RSS)</em>, 2024
            <p style="color: orange; margin: 0px 0;">(Outstanding Student Paper Award Finalist)</p>
            <a href="https://arxiv.org/abs/2401.17583" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://agile-but-safe.github.io/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp 
            <a href="https://github.com/LeCAR-Lab/ABS" target="_blank"><i class="fas fa-code"></i> code</a> &nbsp 
            <a href="https://spectrum.ieee.org/video-friday-agile-but-safe" target="_blank"><i class="fas fa-newspaper"></i> IEEE Spectrum</a> &nbsp
            <a href="https://www.ri.cmu.edu/collision-free-high-speed-robots/" target="_blank"><i class="fas fa-newspaper"></i> CMU News</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: ABS enables fully onboard, agile (>3m/s), and collision-free locomotion for quadrupedal robots in cluttered environments.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_offroad.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Model Predictive Control for Aggressive Driving Over Uneven Terrain</papertitle>
            <br>
            Tyler Han, Alex Liu, Anqi Li, Alex Spitzer, Guanya Shi, Byron Boots
            <br>
            <em>Robotics: Science and Systems (RSS)</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2311.12284" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://sites.google.com/cs.washington.edu/off-road-mpc" target="_blank"><i class="fas fa-globe"></i> website</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We design a terrain-aware MPC framework that enables agile driving over uneven offroad geometries such as hills, banks, and ditches.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_DPO-IK.png' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Propagative Distance Optimization for Constrained Inverse Kinematics</papertitle>
            <br>
            Yu Chen, Yilin Cai, Jinyun Xu, Zhongqiang Ren, Guanya Shi, Howie Choset
            <br>
            <em>International Workshop on the Algorithmic Foundations of Robotics (WAFR)</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2406.11572" target="_blank"><i class="far fa-file"></i> paper</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We propose a fast and scalable method for high-dim constrained IK problems, based on propagative distance-based optimization.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_CoVO-MPC.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>CoVO-MPC: Theoretical Analysis of Sampling-based MPC and Optimal Covariance Design</papertitle>
            <br>
            Zeji Yi<sup>*</sup>, Chaoyi Pan<sup>*</sup>, Guanqi He, Guannan Qu<sup>&dagger;</sup>, Guanya Shi<sup>&dagger;</sup>
            <br>
            <em>Conference on Learning for Dynamics and Control (L4DC)</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2401.07369" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://lecar-lab.github.io/CoVO-MPC/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/LeCAR-Lab/CoVO-MPC" target="_blank"><i class="fas fa-code"></i> code</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We quantify the convergence rate of sampling-based MPC, and design a practical and effective algorithm CoVO-MPC with optimal rate.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_HMAC.png ' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Hierarchical Meta-learning-based Adaptive Controller</papertitle>
            <br>
            Fengze Xie, Guanya Shi,  Michael O'Connell, Yisong Yue, Soon-Jo Chung
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2311.12367" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://sites.google.com/view/hmacproject" target="_blank"><i class="fas fa-globe"></i> website</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: HMAC handles both manageable and latent disturbances with hierarchical iterative learning and smoothed streaming meta-learning.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_SafeDPA.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Safe Deep Policy Adaptation</papertitle>
            <br>
            Wenli Xiao<sup>*</sup>, Tairan He<sup>*</sup>, John Dolan, Guanya Shi
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2310.08602" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://sites.google.com/view/safe-deep-policy-adaptation" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://youtu.be/PkyRzlRQVbE?si=B3guhmFEJyFhhgiS" target="_blank"><i class="fas fa-video"></i> video</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: SafeDPA jointly tackles the problems of policy adaptation and safe reinforcement learning, under unseen disturbances in the real world.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_DMPO.png' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Deep Model Predictive Optimization</papertitle>
            <br>
            Jacob Sacks, Rwik Rana, Kevin Huang, Alex Spitzer, Guanya Shi, Byron Boots
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2024
            <br>            
            <a href="https://arxiv.org/abs/2310.04590" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://sites.google.com/uw.edu/dmpo" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/jisacks/dmpo" target="_blank"><i class="fas fa-code"></i> code</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: DMPO learns the inner-loop optimizer of sampling-based MPC directly via experience, outperforming MPC and end-to-end RL baselines.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_aerial_interaction.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Aerial Interaction with Tactile Sensing</papertitle>
            <br>
            Xiaofeng Guo, Guanqi He, Mohammadreza Mousaei, Junyi Geng, Guanya Shi, Sebastian Scherer
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2024
            <br>            
            <a href="https://arxiv.org/abs/2310.00142" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://sites.google.com/view/aerial-system-gelsight" target="_blank"><i class="fas fa-globe"></i> website</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We introduce a new aerial manipulation system that leverages tactile feedback for accurate contact force control and texture detection.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2024_gyf.gif' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Guardians as You Fall: Active Mode Transition for Safe Falling</papertitle>
            <br>
            Yikai Wang, Mengdi Xu, Guanya Shi, Ding Zhao
            <br>
            <em>IEEE International Automated Vehicle Validation Conference (IAVVC)</em>, 2024
            <p style="color: orange; margin: 0px 0;">(Best Paper Award - Innovation)</p>
            <a href="https://arxiv.org/abs/2310.04828" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://sites.google.com/view/guardians-as-you-fall/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/ykwang20/Guardians_as_You_Fall" target="_blank"><i class="fas fa-code"></i> code</a> &nbsp
            <a href="https://youtu.be/e0ORrUjrncc?si=oQwIA9tf8VHGk8D6" target="_blank"><i class="fas fa-video"></i> video</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: GYF is a safe falling and recovery framework that can actively tumble and recover to stable modes to reduce damage.
            </p>
        </td>
    </tr>
    </table>

    <br> 
    <br>   

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td width="100%" valign="middle">
            <heading>2023</heading>
        </td>
    </tr>
    </table>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2023_optimal_exploration.png' width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Optimal Exploration for Model-based RL in Nonlinear Systems</papertitle>
            <br>
            Andrew Wagenmaker, Guanya Shi, Kevin Jamieson
            <br>
            <em>Neural Information Processing Systems (NeurIPS)</em>, 2023
            <p style="color: orange; margin: 0px 0;">(Spotlight, 3.1%)</p>
            <a href="https://arxiv.org/abs/2306.09210" target="_blank"><i class="far fa-file"></i> paper</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: Not all model parameters are equally important. We develop an instance-optimal exploration algorithm for MBRL in nonlinear systems.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2023_active_learning.png' width="85%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Active Representation Learning for General Task Space with Applications in Robotics</papertitle>
            <br>
            Yifang Chen, Yingbing Huang, Simon S. Du, Kevin Jamieson, Guanya Shi
            <br>
            <em>Neural Information Processing Systems (NeurIPS)</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2306.08942" target="_blank"><i class="far fa-file"></i> paper</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: Inspired by robotics applications, we study algorithms for active representation learning with continuous task parametrization.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2023_datt.gif' width="62%">
                <img src='publications/2023_datt.png' width="38%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>DATT: Deep Adaptive Trajectory Tracking for Quadrotor Control</papertitle>
            <br>
            Kevin Huang, Rwik Rana, Alexander Spitzer, Guanya Shi, Byron Boots
            <br>
            <em>Conference on Robot Learning (CoRL)</em>, 2023
            <p style="color: orange; margin: 0px 0;">(Oral presentation, 6.6%)</p>
            <a href="https://openreview.net/pdf?id=XEw-cnNsr6" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://sites.google.com/view/deep-adaptive-traj-tracking" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/KevinHuang8/DATT" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: DATT can precisely track arbitrary, potentially infeasible trajectories in the presence of large disturbances.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src='publications/2023_cajun.gif' width="100%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>CAJun: Continuous Adaptive Jumping using a Learned Centroidal Controller</papertitle>
            <br>
            Yuxiang Yang, Guanya Shi, Xiangyun Meng, Wenhao Yu, Tingnan Zhang, Jie Tan, Byron Boots
            <br>
            <em>Conference on Robot Learning (CoRL)</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2306.09557" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://youtu.be/uWofjeirdEY" target="_blank"><i class="fas fa-video"></i> video</a> &nbsp
            <a href="https://yxyang.github.io/cajun/" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://github.com/yxyang/cajun" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: CAJun is a hierarchical learning and control framework that enables legged robots to jump continuously with adaptive distances.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <img src='publications/2023_power_adaptive.png' width="100%">
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Leveraging Predictions in Power System Frequency Control: an Adaptive Approach</papertitle>
            <br>
            Wenqi Cui, Guanya Shi, Yuanyuan Shi, Baosen Zhang
            <br>
            <em>IEEE Conference on Decision and Control (CDC)</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2305.12044" target="_blank"><i class="far fa-file"></i> paper</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We combine adaptive nonlinear control and neural control for frequency restoration in power systems.
            </p>
        </td>
    </tr>
    </table>

    <br>
    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td width="100%" valign="middle">
            <heading>2022</heading>
        </td>
    </tr>
    </table>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <img src='publications/2022_neural_fly.gif' width="90%">
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Neural-Fly Enables Rapid Learning for Agile Flight in Strong Winds</papertitle>
            <br>
            Michael O'Connell<sup>*</sup>, Guanya Shi<sup>*</sup>, Xichen Shi, Kamyar Azizzadenesheli, Animashree Anandkumar, Yisong Yue, Soon-Jo Chung
            <br>
            <em>Science Robotics</em>
            <br>
            <a href="https://arxiv.org/abs/2205.06908" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://youtu.be/TuF9teCZX0U" target="_blank"><i class="fas fa-video"></i> video</a> &nbsp
            <a href="https://www.caltech.edu/about/news/rapid-adaptation-of-deep-learning-teaches-drones-to-survive-any-weather" target="_blank"><i class="fas fa-newspaper"></i> Caltech news</a> &nbsp
            <a href="https://youtu.be/R1S5BnKgJxs" target="_blank"><i class="fas fa-newspaper"></i> Reuters</a> &nbsp
            <a href="https://www.cnn.com/videos/business/2022/05/31/caltech-neural-fly-drones-in-strong-wind-orig-ht.cnn-business/video/playlists/business-tech/" target="_blank"><i class="fas fa-newspaper"></i> CNN</a> &nbsp
            <a href="https://github.com/aerorobotics/neural-fly" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: Neural-Fly uses adaptive control to online fine-tune a meta-pretrained DNN representation, enabling rapid adaptation in strong winds. 
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src="publications/2022_soco_delay_nonlinear.png" width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Online Optimization with Feedback Delay and Nonlinear Switching Cost</papertitle>
            <br>
            Weici Pan, Guanya Shi, Yiheng Lin, Adam Wierman
            <br>
            <em>Proceedings of the ACM on Measurement and Analysis of Computing Systems (SIGMETRICS)</em>
            <br>
            <a href="https://dl.acm.org/doi/abs/10.1145/3508037" target="_blank"><i class="far fa-file"></i> paper</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We propose a new online optimization setting with delay and nonlinear switching cost, and provide compeititve algorithms.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src="publications/2022_robustness_consistency.png" width="100%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Robustness and Consistency in Linear Quadratic Control with Predictions</papertitle>
            <br>
            Tongxin Li<sup>*</sup>, Ruixiao Yang<sup>*</sup>, Guannan Qu, Guanya Shi, Chenkai Yu, Adam Wierman, Steven Low
            <br>
            <em>Proceedings of the ACM on Measurement and Analysis of Computing Systems (SIGMETRICS)</em>
            <br>
            <a href="https://dl.acm.org/doi/abs/10.1145/3508038" target="_blank"><i class="far fa-file"></i> paper</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: For online control with noisy predictions, we design an algorithm to optimally balance robustness and consistency (performance if no noise).
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src="publications/2022_delayed_imperfect_information.png" width="100%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Competitive Control with Delayed Imperfect Information</papertitle>
            <br>
            Chenkai Yu, Guanya Shi, Soon-Jo Chung, Yisong Yue, Adam Wierman
            <br>
            <em>American Control Conference (ACC)</em>, 2022
            <br>
            <a href="https://ieeexplore.ieee.org/abstract/document/9867421" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://www.gshi.me/blog/CompetitiveMPC/" target="_blank"><i class="fas fa-file-alt"></i> blog</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We study MPC's dynamic regret and competitive ratio in the presence of prediction inaccuracy and feedback delay.
            </p>
        </td>
    </tr>
    </table>

    <br>
    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td width="100%" valign="middle">
            <heading>2021</heading>
        </td>
    </tr>
    </table>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src="publications/2021_perturbation_mpc.png" width="100%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Perturbation-based Regret Analysis of Predictive Control in LTV Systems</papertitle>
            <br>
            Yiheng Lin<sup>*</sup>, Yang Hu<sup>*</sup>, Guanya Shi<sup>*</sup>, Haoyuan Sun<sup>*</sup>, Guannan Qu<sup>*</sup>, Adam Wierman
            <br>
            <em>Neural Information Processing Systems (NeurIPS)</em>, 2021
            <p style="color: orange; margin: 0px 0;">(Spotlight, 2.9%)</p>
            <a href="https://proceedings.neurips.cc/paper/2021/hash/298f587406c914fad5373bb689300433-Abstract.html" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://www.gshi.me/blog/CompetitiveMPC/" target="_blank"><i class="fas fa-file-alt"></i> blog</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We prove MPC's dynamic regret and competitive ratio exponentially improve as its prediction gets longer, in LTV systems.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src="publications/2021_OMAC.gif" width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Meta-Adaptive Nonlinear Control: Theory and Algorithms</papertitle>
            <br>
            Guanya Shi, Kamyar Azizzadenesheli, Michael O'Connell, Soon-Jo Chung, Yisong Yue
            <br>
            <em>Neural Information Processing Systems (NeurIPS)</em>, 2021
            <br>
            <a href="https://arxiv.org/abs/2106.06098" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://github.com/GuanyaShi/Online-Meta-Adaptive-Control" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We present an online multi-task learning approach for adaptive nonlinear control with non-asymptotic guarantees.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src="publications/2021_fast_uq.png" width="85%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Fast Uncertainty Quantification for Deep Object Pose Estimation</papertitle>
            <br>
            Guanya Shi, Yifeng Zhu, Jonathan Tremblay, Stan Birchfield, Fabio Ramos, Animashree Anandkumar, Yuke Zhu
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2021
            <br>
            <a href="https://arxiv.org/abs/2011.07748" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://sites.google.com/view/fastuq" target="_blank"><i class="fas fa-globe"></i> website</a> &nbsp
            <a href="https://developer.nvidia.com/blog/nvidia-research-fast-uncertainty-quantification-for-deep-object-pose-estimation/" target="_blank"><i class="fas fa-file-alt"></i> blog</a> &nbsp
            <a href="https://github.com/NVlabs/DOPE-Uncertainty" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We develop a simple and efficient UQ method for 6-DoF pose estimation, and apply it in real-world grasping tasks.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <img src='publications/2021_neural_swarm.gif' width="90%">
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Neural-Swarm2: Planning and Control of Heterogeneous Multirotor Swarms Using Learned Interactions</papertitle>
            <br>
            Guanya Shi, Wolfgang Hnig, Xichen Shi, Yisong Yue, Soon-Jo Chung
            <br>
            <em>IEEE Transactions on Robotics</em>
            <br>
            <a href="https://arxiv.org/abs/2012.05457" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://youtu.be/Y02juH6BDxo" target="_blank"><i class="fas fa-video"></i> video</a> &nbsp
            <a href="https://www.caltech.edu/about/news/machine-learning-helps-robot-swarms-coordinate" target="_blank"><i class="fas fa-newspaper"></i> Caltech news</a> &nbsp
            <a href="https://news.yahoo.com/caltech-drone-swarm-ai-174642584.html" target="_blank"><i class="fas fa-newspaper"></i> Yahoo! news</a> &nbsp
            <a href="https://github.com/aerorobotics/neural-swarm" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: Neural-Swarm is a learning-based controller and planner for close-proximity flight of heterogeneous multirotor swarms.
            </p>
        </td>
    </tr>
    </table>

    <br>
    <br>    

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td width="100%" valign="middle">
            <heading>2020</heading>
        </td>
    </tr>
    </table>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src="publications/2020_info_snoc.png" width="80%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Chance-Constrained Trajectory Optimization for Safe Exploration and Learning of Nonlinear Systems</papertitle>
            <br>
            Yashwanth Kumar Nakka, Anqi Liu, Guanya Shi, Animashree Anandkumar, Yisong Yue, Soon-Jo Chung
            <br>
            <em>IEEE Robotics and Automation Letters (RA-L)</em>
            <br>
            <a href="https://arxiv.org/abs/2005.04374" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://yashwanthnakka.com/trajectory-optimization-for-safe-exploration/" target="_blank"><i class="fas fa-file-alt"></i> blog</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We derive an iterative algorithm to solve information-cost stochastic nonlinear optimal control problems for safe episodic learning.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <img src='publications/2020_robust_regression.png' width="100%">
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Robust Regression for Safe Exploration in Control</papertitle>
            <br>
            Anqi Liu, Guanya Shi, Soon-Jo Chung, Animashree Anandkumar, Yisong Yue
            <br>
            <em>Conference on Learning for Dynamics and Control (L4DC)</em>, 2020
            <br>
            <a href="https://arxiv.org/pdf/1906.05819" target="_blank"><i class="far fa-file"></i> paper</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We derive generalization bounds under domain shift and connect them with safety bounds in control, for end-to-end safe explorations.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <img src='publications/2020_mpc.png' width="100%">
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>The Power of Predictions in Online Control</papertitle>
            <br>
            Chenkai Yu, Guanya Shi, Soon-Jo Chung, Yisong Yue, Adam Wierman
            <br>
            <em>Neural Information Processing Systems (NeurIPS)</em>, 2020
            <br>
            <a href="https://arxiv.org/abs/2006.07569" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://videos.neurips.cc/search/power%20of%20predictions%20in%20online%20control/video/slideslive-38936069" target="_blank"><i class="fas fa-video"></i> video</a> &nbsp
            <a href="https://www.gshi.me/blog/CompetitiveMPC/" target="_blank"><i class="fas fa-file-alt"></i> blog</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We give the first non-asymptotic guarantee for MPC. MPC's dynamic regret exponentially decreases as its prediction gets longer.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src="publications/2020_optimistic_robd.png" width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Online Optimization with Memory and Competitive Control</papertitle>
            <br>
            Guanya Shi<sup>*</sup>, Yiheng Lin<sup>*</sup>, Soon-Jo Chung, Yisong Yue, Adam Wierman
            <br>
            <em>Neural Information Processing Systems (NeurIPS)</em>, 2020
            <br>
            <a href="https://arxiv.org/abs/2002.05318" target="_blank"><i class="far fa-file"></i> paper</a> 
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We show competitive algorithms for a new class of online optimization problems, with applications in online competitive control.
            </p>
        </td>
    </tr>
    </table>

    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <div class="image-container">
                <img src="publications/2020_neural_swarm.png" width="90%">
            </div>
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Neural-Swarm: Decentralized Close-Proximity Multirotor Control Using Learned Interactions</papertitle>
            <br>
            Guanya Shi, Wolfgang Hnig, Yisong Yue, Soon-Jo Chung
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2020
            <br>
            <a href="https://ieeexplore.ieee.org/abstract/document/9196800" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://youtu.be/v4j-9pH11Q8" target="_blank"><i class="fas fa-video"></i> video</a> &nbsp
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We deploy Deep Sets to learn complex interactions between multirotors, for decentralized close-proximity control.
            </p>
        </td>
    </tr>
    </table>

    <br>
    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td width="100%" valign="middle">
            <heading>2019</heading>
        </td>
    </tr>
    </table>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr style="background-color: var(--highlight-color)">
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <img src='publications/2019_neural_lander.gif' width="90%">
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Neural Lander: Stable Drone Landing Control Using Learned Dynamics</papertitle>
            <br>
            Guanya Shi<sup>*</sup>, Xichen Shi<sup>*</sup>, Michael O'Connell<sup>*</sup>, Rose Yu, Kamyar Azizzadenesheli, Animashree Anandkumar, Yisong Yue, Soon-Jo Chung
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2019
            <br>
            <a href="https://arxiv.org/abs/1811.08027" target="_blank"><i class="far fa-file"></i> paper</a> &nbsp
            <a href="https://youtu.be/FLLsG0S78ik" target="_blank"><i class="fas fa-video"></i> video</a> &nbsp
            <a href="https://www.caltech.edu/about/news/neural-lander-uses-ai-land-drones-smoothly" target="_blank"><i class="fas fa-newspaper"></i> Caltech homepage news</a> &nbsp
            <a href="https://github.com/GuanyaShi/neural_lander_sim_1d" target="_blank"><i class="fas fa-code"></i> code</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: Spectrally normalized deep learning and nonlinear control enable provably stable agile drone landing.
            </p>
        </td>
    </tr>
    </table>

    <br>
    <br>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td width="100%" valign="middle">
            <heading>2018</heading>
        </td>
    </tr>
    </table>

    <table width="880" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td style="width:35%; vertical-align:middle; padding-right: 20px;">
            <img src='publications/2018_car_following.png' width="90%">
        </td>
        <td style="width:65%; vertical-align:middle">
            <papertitle>Car-following Method Based on Inverse Reinforcement Learning for Autonomous Vehicle Decision-making</papertitle>
            <br>
            Hongbo Gao, Guanya Shi, Guotao Xie, Bo Cheng
            <br>
            <em>International Journal of Advanced Robotic Systems</em>
            <br>
            <a href="https://journals.sagepub.com/doi/full/10.1177/1729881418817162" target="_blank"><i class="far fa-file"></i> paper</a>
            <p style="margin-top: 5px"><i class="fas fa-comment-dots"></i> TL;DR: We use inverse RL to learn reward models for human-like autonomous car following.
            </p>
        </td>
    </tr>
    </table>

    <br>
    <br>
    <br>

</body>


</html>